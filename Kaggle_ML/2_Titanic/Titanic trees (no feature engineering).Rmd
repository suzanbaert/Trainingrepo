---
title: "Titanic Trees Training"
output: html_document
---

```{r setup}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)

library(readr)
library(dplyr)
library(Metrics)

titanic <- read_csv(here::here("Kaggle_ML", "2_Titanic", "data", "train.csv"))

set.seed(123)
test_index <- sample(1:nrow(titanic), size =0.15*nrow(titanic))
titanic_test <- titanic[test_index, ]
titanic_train <- titanic[-test_index, ]

glimpse(titanic)
```


# Decision trees


### 1. Standard decision tree - no pruning

```{r}
library(rpart)
library(rpart.plot)

dt_model <- rpart(Survived ~ Pclass + Sex + Age + Fare + Embarked, 
                  data = titanic_train,
                  method = "class")

rpart.plot(dt_model)

```


Getting accuracy and confusionMatrix.
Accuracy is 0.812


```{r}
dt_pred <- predict(dt_model, titanic_test, type = "class")

#Accuracy
paste("Accuracy:", mean(dt_pred == titanic_test$Survived))

#Classification error
paste("Classificaton error", ce(actual = titanic_test$Survived, predicted = dt_pred))

#Pretty much everything
caret::confusionMatrix(dt_pred, reference = as.factor(titanic_test$Survived))

```

To get to auc, first redo predictions to get to prob.
- For auc, should not forget to put the second column of the predicted values, otherwise odd things are happening :)


```{r}
#generate probability prediction
dt_pred_p <- predict(dt_model, titanic_test, type = "prob")

#auc
dt_auc <- auc(actual = titanic_test$Survived, predicted = dt_pred_p[, 2])
dt_auc

```

<br>


### 2. Decision tree - via cp optimal

```{r}

#plotcp
plotcp(dt_model)

#optimal cp
dt_model$cptable
cp_opt_index <- which.min(dt_model$cptable[ , "xerror"])
cp_opt <- dt_model$cptable[cp_opt_index, "CP"]

```


New tree postpruned:


```{r}
dt_model_cpopt <- prune(dt_model, cp = cp_opt)
rpart.plot(dt_model_cpopt)
```

- After pruning, accuracy and classification error are similar
- AUC went down from 0,833 to 0,796


```{r}
dt_pred_cpopt <- predict(dt_model_cpopt, titanic_test, type = "class")

#accuracy/ce
paste("Accuracy:", mean(dt_pred == titanic_test$Survived))
paste("Classificaton error", ce(actual = titanic_test$Survived, predicted = dt_pred))
caret::confusionMatrix(data = dt_pred_cpopt, reference = as.factor(titanic_test$Survived))

#auc
dt_pred_cpopt_prob <- predict(dt_model_cpopt, titanic_test, type = "prob")
paste("auc:", auc(actual = titanic_test$Survived, predicted = dt_pred_cpopt_prob[ , 2]))

```

<br>

### 3. Grid search

Possible tuning parameters:
- maxdepth
- minsplit
- cp
- impurity index via "Gini index" or "information"

```{r}

maxdepth = seq(2, 10, 1)
minsplit = seq(5, 50, 5)
cp = seq(0.01, 0.02, 0.001)
index = c("gini", "information")

hypergrid <- expand.grid(minsplit = minsplit, maxdepth = maxdepth, cp = cp, index = index)
dt_gsmodels <- list()

for (i in 1:nrow(hypergrid)) {
  dt_gsmodels[[i]] <- rpart(Survived ~ Pclass + Sex + Age + Fare + Embarked, 
                  data = titanic_train,
                  method = "class",
                  control = rpart.control(cp = hypergrid$cp[i], minsplit = hypergrid$minsplit[i], maxdepth = hypergrid$maxdepth[i]),
                  parms = list(split = hypergrid$index[i]))
}

```


Predictions on 1980 models:

```{r}

for (i in 1:length(dt_gsmodels)) {
  pred_class <- predict(dt_gsmodels[[i]], titanic_test, type = "class")
  hypergrid$accuracy[i] <- mean(pred_class == titanic_test$Survived)
  hypergrid$ce[i] <- ce(actual = titanic_test$Survived, predicted = pred_class)
  
  pred_prob <- predict(dt_gsmodels[[i]], titanic_test, type = "prob")
  hypergrid$auc[i] <- auc(actual = titanic_test$Survived, predicted = pred_prob[ ,2])
  }


```



Finding the best models
- accuracy varies from 0.789 until 0.819
- classificaiton error from 0,18 to 0,21
- auc from 0,757 to 0,844


18 models with max auc
- all have cp  0.01 and information index
- maxdepth higher than 5 (no change in any number afterwards)
- minsplit between 5-15


```{r}
hypergrid %>% 
  filter(auc == max(auc))
```

```{r}
dt_model_opt <- rpart(Survived ~ Pclass + Sex + Age + Fare + Embarked, 
                  data = titanic_train,
                  method = "class",
                  control = rpart.control(cp = 0.01, minsplit = 10, maxdepth = 5),
                  parms = list(split = "information"))

rpart.plot(dt_model_opt)

```

